{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle pour 52 fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import os\n",
    "import cv2 as cv\n",
    "\n",
    "#partie sklearn\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#partie tensorFLow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128 #taille des images\n",
    "nbDir=52 #nombre de fichiers de fleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 1: Nettoyage des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "FlowerPath='../../flower52'\n",
    "\n",
    "#récupération des images et des noms d'espèces   \n",
    "os.listdir(FlowerPath)\n",
    "for folder in os.listdir(FlowerPath):\n",
    "    for file in os.listdir(os.path.join(FlowerPath,folder)):\n",
    "        if  file.endswith(\"jpeg\"):\n",
    "            label.append(folder) #on met le nom des dossiers (des espèces) dans label\n",
    "            img = cv.imread(os.path.join(FlowerPath,folder, file))\n",
    "            img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            im = cv.resize(img_rgb, (size,size)) #recadre les images\n",
    "            data.append(im) #on met les images dans data\n",
    "                    \n",
    "        else: \n",
    "            continue\n",
    "\n",
    "data_arr = np.array(data)\n",
    "label_arr = np.array(label)\n",
    "y = LabelEncoder().fit_transform(label_arr)\n",
    "y = to_categorical(y,nbDir)\n",
    "X = data_arr/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 2: Séparation des données, 20% dans test et le reste dans train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range = 0.20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 3: Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = size/2, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (size,size,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = size/4, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(Conv2D(filters = size/2, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(Conv2D(filters = size, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(size, activation='relu'))\n",
    "model.add(Dense(size/2, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(nbDir, activation = \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 4: Premier entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "batch_size=32\n",
    "epochs=20\n",
    "\n",
    "checkpoint_path = \"modele52/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs,\n",
    "                              validation_data = (X_test,y_test),   \n",
    "                              verbose = 1,\n",
    "                              callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 5: premier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.sort(os.listdir(FlowerPath))\n",
    "fig, ax = plt.subplots(4,4, figsize=(25, 40))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        k = int(np.random.random_sample() * len(X_test))\n",
    "        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n",
    "            ax[i,j].set_title(\"VRAI: \" + categories[np.argmax(y_test[k])], color='green')\n",
    "            ax[i,j].set_xlabel(\"PREDICTION: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n",
    "            ax[i,j].imshow(np.array(X_test)[k].reshape(size, size, 3), cmap='gray')\n",
    "        else:\n",
    "            ax[i,j].set_title(\"VRAI: \" + categories[np.argmax(y_test[k])], color='red')\n",
    "            ax[i,j].set_xlabel(\"PREDICTION: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n",
    "            ax[i,j].imshow(np.array(X_test)[k].reshape(size, size, 3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 6: Sauvegarde du modèle en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('modele52/my_model') #si décommenté écrase le modèle précédant\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a13787ef1c4fcd089a917e91a1d39bad82f0cc1a097c16f88f4ddd436f64cc5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
